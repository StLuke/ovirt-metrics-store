---
- name: Configure /etc/hosts for engine machine
  hosts: all
  tasks:
    - set_fact:
        metrics_store_fqdn: "{{ hostvars[groups['metrics-store'][0]]['ansible_fqdn'] }}"
        metrics_store_ip: "{{ groups['metrics-store'][0] }}"
    - name: edit /etc/hosts
      lineinfile:
        dest: "/etc/hosts"
        line: "{{ metrics_store_ip }} {{ metrics_store_fqdn}} kopf.{{ metrics_store_fqdn}} mux.{{ metrics_store_fqdn}} openshift.{{ metrics_store_fqdn}} kibana.{{ metrics_store_fqdn}} es.{{ metrics_store_fqdn}}"

- name: Provisioning a machine to run ViaQ
  hosts: metrics-store
  tasks:
    - name: Save metrics store machine fqdn
      set_fact:
        metrics_store_fqdn: "{{ hostvars[groups['metrics-store'][0]]['ansible_fqdn'] }}"
    - name: Creates .ssh directory
      file:
        path: /root/.ssh
        state: directory
    - name: ViaQ on Origin requires these Yum Repo
      copy:
        src: ../conf/openshift.repo
        dest: /etc/yum.repos.d/
        mode: 0644
        backup: yes
    - name: install the following necessary packages
      yum:
        name: "{{ item }}"
        state: "present"
      with_items:
        - "docker"
        - "iptables"
        - "iptables-services"
        - "NetworkManager"
        - "policycoreutils-python"
        - "git"
        - "net-tools"
        - "bind-utils"
        - "bridge-utils"
        - "bash-completion"
        - "kexec-tools"
        - "sos"
        - "psacct"
        - "atomic-openshift-utils"
        - "atomic-openshift-excluder"
        - "atomic-openshift-docker-excluder"
    - name: Remove old ssh key
      file:
        state: absent
        path: /root/.ssh/id_rsa
    - name: provide an ssh pubkey for this user account
      shell: ssh-keygen -b 2048 -t rsa -f /root/.ssh/id_rsa -q -N ""
    - name: add the ssh pubkey to the user account
      shell: cat /root/.ssh/id_rsa.pub >> /root/.ssh/authorized_keys
    - name: add the ssh hostkey for localhost to your SSH known_hosts
      shell: ssh-keyscan -H localhost >> /root/.ssh/known_hosts
    - name: add the ssh hostkey for public_hostname to your SSH known_hosts
      shell: ssh-keyscan -H  "{{ metrics_store_fqdn }}" >> /root/.ssh/known_hosts
    - name: allow connections on the following ports/protocols 22, 80, 443, 8443, 24284
      shell: "iptables -I INPUT -p tcp --dport {{ item }} -j ACCEPT"
      with_items:
        - 80
        - 443
        - 8443
        - 24284
        - 9200
    - name: You'll also need to enable and start NetworkManager
      service:
        name: NetworkManager
        state: started
        enabled: yes
    - name: ensure file exists
      file:
        path: /etc/sudoers.d/999-cloud-init-requiretty
        state: touch
    - name: need to configure sudo to not require a tty
      lineinfile:
        dest: /etc/sudoers.d/999-cloud-init-requiretty
        line: 'Defaults !requiretty'


- name: Make persistent storage
  hosts: metrics-store
  tasks:
    - name: Creates directory for storage
      file:
        path: /var/lib/elasticsearch
        state: directory
        mode: 0660
    - name: Change group owner
      shell: chgrp 65534 /var/lib/elasticsearch
    - name: Change context
      shell: semanage fcontext -a -t svirt_sandbox_file_t "/var/lib/elasticsearch(/.*)?"
    - name: Restore context
      shell: restorecon -R -v /var/lib/elasticsearch



- name: Installing ViaQ
  hosts: metrics-store
  tasks:
    - name: install packages
      yum:
        name: "{{ item }}"
        state: "present"
      with_items:
        - "openshift-ansible"
        - "openshift-ansible-callback-plugins"
        - "openshift-ansible-filter-plugins"
        - "openshift-ansible-lookup-plugins"
        - "openshift-ansible-playbooks"
        - "openshift-ansible-roles"
    - name: Run viaq playbooks
      shell: ANSIBLE_LOG_PATH=/tmp/ansible.log ansible-playbook -v -e @/root/vars.yml -i /root/ ansible-inventory-origin-36-aio /usr/share/ansible/openshift-ansible/playbooks/byo/config.yml
    - name: change project
      shell: oc project logging
    - name: Wait for all pods up
      shell: oc get pods --no-headers=true | sed 's/^[a-z0-9-]* *[0-9/]* *\([a-zA-Z]*\) .*$/\1/g' | uniq
      register: pod_status
      retries: 15
      delay: 60
      until: ( "Running" in pod_status.stdout )
    - set_fact:
        metrics_store_ip: "{{ hostvars[groups['metrics-store'][0]]['ansible_default_ipv4']['address'] }}"
    - name: Open elasticsearch for connection
      shell: "oc patch svc logging-es -p '{\"spec\":{\"externalIPs\":[\"{{ metrics_store_ip }}\"]}}'"
    - name: edit configmap to store only last 3 days
      shell: "oc patch configmap logging-curator -p '{\"data\":{\"config.yaml\":\"# Logging example curator config file\\novirt-metrics-test:\\n  delete:\\n    days: 3\\n# uncomment and use this to override the defaults from env vars\\n#.defaults:\\n#  delete:\\n#    days: 30\\n#  runhour: 0\\n#  runminute: 0\\n\\n# to keep ops logs for a different duration:\\n#.operations:\\n#  delete:\\n#    weeks: 8\\n\\n# example for a normal project\\n#myapp:\\n#  delete:\\n#    weeks: 1\\n\"}}'"


- name: Enable elasticsearch mount
  hosts: metrics-store
  tasks:
    - name: change project
      shell: oc project logging
    - name: Add permissions to the directory
      shell: oadm policy add-scc-to-user hostmount-anyuid system:serviceaccount:logging:aggregated-logging-elasticsearch
    - name: Cancel last rollout
      shell: oc rollout cancel $( oc get -n logging dc -l component=es -o name )
    - name: Wait till done
      shell: oc rollout status -w $( oc get -n logging dc -l component=es -o name )
    - name: Get latest version
      shell: oc rollout latest $( oc get -n logging dc -l component=es -o name )
    - name: Wait till done
      shell: oc rollout status -w $( oc get -n logging dc -l component=es -o name )

- name: Run ansible playbook to connect to metrics store
  hosts: engine
  tasks:
    - name: Run metrics playbook
      shell: /usr/share/ovirt-engine-metrics/setup/ansible/configure_ovirt_machines_for_metrics.sh
